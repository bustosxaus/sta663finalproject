{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from Algorithm 1: HMC, page1353\n",
    "def Leapfrog(theta, r, grad, eps, L):\n",
    "    r_tilde = r + (eps/2) * grad\n",
    "    theta_tilde = theta + eps * r_tilde\n",
    "    logp_tilde, grad_tilde = L(theta_tilde)\n",
    "    r_tilde = r_tilde + (eps/2) * grad_tilde\n",
    "    return theta_tilde, r_tilde, grad_tilde, logp_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FindReasonableEpsilon(theta, grad, logp, L):\n",
    "    #initialize\n",
    "    parems = len(theta)\n",
    "    eps = 1\n",
    "    r = np.random.multivariate_normal(np.zeros(parems), np.identity(parems), 1)\n",
    "    r = r.ravel()\n",
    "    theta_prime, r_prime, _, logp_prime = Leapfrog(theta, r, grad, eps, L)\n",
    "    \n",
    "    prob = np.exp(logp_prime - logp - 0.5 * (np.dot(r_prime, r_prime) - np.dot(r, r)))\n",
    "    a = 2 * int(prob > 0.5) - 1\n",
    "\n",
    "    while prob**a > 2**(-a):\n",
    "        eps = 2**a * eps\n",
    "        theta_prime, r_prime, _, logp_prime = Leapfrog(theta, r, grad, eps, L);\n",
    "        prob = np.exp(logp_prime - logp - 0.5 * (np.dot(r_prime, r_prime) - np.dot(r,r)))\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BuildTree(theta, r, grad, u, v, j, eps, L, esto0):\n",
    "    if j == 0: \n",
    "        # base case, take one leapfrog step in the direction v\n",
    "        theta_prime, r_prime, grad_prime, logp_prime = Leapfrog(theta, r, grad, v*eps, L)\n",
    "        \n",
    "        esto = logp_prime - 0.5 * np.dot(r_prime, r_prime)\n",
    "\n",
    "        n_prime = int(u <= np.exp(esto))\n",
    "        \n",
    "        s_prime = int(esto > np.log(u) - 1000)\n",
    "\n",
    "        alpha_prime = min(1, np.exp(esto - esto0))\n",
    "                                                   \n",
    "        return theta_prime, r_prime, grad_prime, theta_prime, r_prime, grad_prime, theta_prime, grad_prime, logp_prime, n_prime, s_prime, alpha_prime, 1\n",
    "    else:\n",
    "        # recursion, build left and right subtrees\n",
    "        theta_minus, r_minus, grad_minus, theta_plus, r_plus, grad_plus, theta_prime, grad_prime, logp_prime, n_prime, s_prime, alpha_prime, n_alpha_prime = BuildTree(theta, r, grad, u, v, j-1, eps, f, esto0)\n",
    "        \n",
    "        if s_prime == 1:\n",
    "            if v == -1:\n",
    "                theta_minus, r_minus, grad_minus, _,_,_, theta_doub_prime, grad_doub_prime, logp_doub_prime, n_doub_prime, s_doub_prime, alpha_doub_prime, n_alpha_doub_prime = BuildTree(theta_minus, r_minus, grad_minus, u, v, j-1, eps, f, esto0)\n",
    "            else:\n",
    "                _, _, _, theta_plus, r_plus, grad_plus, theta_doub_prime, grad_doub_prime, logp_doub_prime, n_doub_prime, s_doub_prime, alpha_doub_prime, n_alpha_doub_prime = BuildTree(theta_plus, r_plus, grad_plus, u, v, j-1, eps, f, esto0)\n",
    "\n",
    "            # Use Metropolis-Hastings\n",
    "            prob = n_doub_prime / max(n_prime + n_doub_prime,1)\n",
    "            if (np.random.uniform(0, 1, 1) < prob):\n",
    "                theta_prime = theta_doub_prime\n",
    "                grad_prime = grad_doub_prime\n",
    "                logp_prime = logp_doub_prime\n",
    "            \n",
    "            ind_1 = int(np.dot(theta_plus-theta_minus, r_minus) >= 0)\n",
    "            ind_2 = int(np.dot(theta_plus-theta_minus, r_plus) >= 0)\n",
    "            s_prime = s_prime * s_doub_prime * ind_1 * ind_2\n",
    "            n_prime = n_prime + n_doub_prime\n",
    "            alpha_prime = alpha_prime + alpha_doub_prime\n",
    "            n_alpha_prime = n_alpha_prime + n_alpha_doub_prime\n",
    "        \n",
    "        return theta_minus, r_minus, grad_minus, theta_plus, r_plus, grad_plus, theta_prime, grad_prime, logp_prime, n_prime, s_prime, alpha_prime, n_alpha_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nuts6_dual_averaging(theta0, M, M_adapt, L, delta = 0.6):\n",
    "    # initialize samples matrix\n",
    "    # put initial theta0 in first row of matrix\n",
    "    parems = len(theta0)\n",
    "    samples = [0] * (M+1)\n",
    "    samples[0] = theta0\n",
    "    logp, grad = L(theta0)\n",
    "    eps = FindReasonableEpsilon(theta0, grad, logp, L)\n",
    "    mu = np.log(10*eps)\n",
    "    eps_bar = 1\n",
    "    H_bar = 0\n",
    "    gamma = 0.05\n",
    "    t0 = 10\n",
    "    k = 0.75\n",
    "    \n",
    "    for m in range(1, M+1):\n",
    "        # resample\n",
    "        norm_samp = np.random.multivariate_normal(np.zeros(parems), np.identity(parems), 1)\n",
    "        r0 = norm_samp.ravel()\n",
    "\n",
    "        esto = logp - 0.5 * np.dot(r0,r0)\n",
    "        # resample u ~ uniform([0, exp(inside)])\n",
    "        u = np.random.uniform(0, np.exp(esto), 1)\n",
    "\n",
    "        # initialize minus's and plus's\n",
    "        theta_minus = samples[m-1]\n",
    "        theta_plus = samples[m-1]\n",
    "        r_minus = r0\n",
    "        r_plus = r0\n",
    "        j = 0\n",
    "        grad_minus = grad\n",
    "        grad_plus = grad\n",
    "        \n",
    "        j = 0\n",
    "        samples[m] = samples[m-1]\n",
    "        n = 1\n",
    "        s = 1\n",
    "        \n",
    "        while s == 1:\n",
    "            v_j = np.random.uniform(-1,1,1)\n",
    "            if v_j == -1:\n",
    "                theta_minus, r_minus, grad_minus, _, _, _, theta_prime, grad_prime, logp_prime, n_prime, s_prime, alpha, n_alpha = BuildTree(theta_minus, r_minus, grad_minus, u, v_j, j, eps, L, esto)\n",
    "            else:\n",
    "                _, _, _, theta_plus, r_plus, grad_plus, theta_prime, grad_prime, logp_prime, n_prime, s_prime, alpha, n_alpha = BuildTree(theta_plus, r_plus, grad_plus, u, v_j, j, eps, L, esto)\n",
    "            \n",
    "            if s_prime == 1:\n",
    "                # Use Metropolis-Hastings\n",
    "                prob = min(1, n_prime/n)\n",
    "                if (np.random.uniform(0,1,1) < prob):\n",
    "                    samples[m] = theta_prime\n",
    "                    logp = logp_prime\n",
    "                    grad = grad_prime\n",
    "                    \n",
    "            n = n + n_prime\n",
    "\n",
    "            boolean_1 = int(np.dot(theta_plus-theta_minus, r_minus) >= 0)\n",
    "            boolean_2 = int(np.dot(theta_plus-theta_minus, r_plus) >= 0)\n",
    "            s = s_prime * boolean_1 * boolean_2\n",
    "            j = j + 1\n",
    "            \n",
    "        if m <= M_adapt:\n",
    "            H_bar = (1 - 1/(m+t0))*H_bar + (1/(m+t0)) * (delta - alpha/n_alpha)\n",
    "            eps = np.exp(mu - np.sqrt(m)/gamma * H_bar)\n",
    "            esp_bar = np.exp(m**(-k) * np.log(eps) + (1-m**(-k))*np.log(eps_bar))\n",
    "        else:\n",
    "            eps = eps_bar\n",
    "            \n",
    "    burned_in = samples[M_adapt+1:M+1]\n",
    "    return burned_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5899999999999999"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.poisson(5, 100)\n",
    "N = 100\n",
    "def L(theta):\n",
    "    grad = sum(X) / theta - N\n",
    "    logp = sum(X)*np.log(theta) - theta*N\n",
    "    return logp, grad\n",
    "np.mean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.601717175446014"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple example\n",
    "theta0 = np.array([10])\n",
    "M = 10000\n",
    "M_adapt = 1000\n",
    "results = nuts6_dual_averaging(theta0, M, M_adapt, L, delta = 0.6)\n",
    "np.mean(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-b21caa1b3f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mempty_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mempty_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# multivariate normal\n",
    "mean = np.array([1,2,3,4,5])\n",
    "cov = np.array([[1, 0, 0, 0, 0], [0, 2, 0, 0, 0], [0, 0, 3, 0, 0], [0, 0, 0, 4, 0], [0, 0, 0, 0, 5]])\n",
    "X = np.random.multivariate_normal(mean, cov, 100)\n",
    "\n",
    "\n",
    "theta = [mean, cov]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-175-6c19102cbef0>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-175-6c19102cbef0>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    def L(theta)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def L(theta)\n",
    "    cumsum = 0\n",
    "    for x in X:\n",
    "        cumsum += (x - theta[0]).T @ np.linalg.inv(theta[1]) @ (x - theta[0])\n",
    "    logp = -0.5 * cumsum\n",
    "    \n",
    "    \n",
    "    \n",
    "    return logp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "def L(theta):\n",
    "    logp = -0.5 * (sum())\n",
    "\n",
    "    one = \n",
    "    two = \n",
    "    grad = np.array([one, two])\n",
    "\n",
    "    return logp, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
